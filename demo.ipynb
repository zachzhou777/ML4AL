{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes over all of the major components of this project:\n",
    "1. Simulation: Can be thought of as a black box that takes in a solution and outputs coverage metrics. Used to evaluate solutions and generate a dataset.\n",
    "2. Machine learning: A multilayer perceptron (MLP) is trained to predict coverage metrics given a solution.\n",
    "3. Optimization: The MLP is embedded within a MIP which attempts to find the solution that the MLP predicts will have the highest coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ems_data import EMSData\n",
    "from simulation import Simulation\n",
    "from multilabel_mlp import MultilabelMLP\n",
    "from mip_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything, we need to load the data. The EMSData class reads and preprocesses the data for usage in simulation and MIP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you already have ems_data.pkl and don't need to regenerate with different parameters\n",
    "ems_data = EMSData()\n",
    "ems_data.save_instance('ems_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# stations: 8\n",
      "# demand nodes: 62\n"
     ]
    }
   ],
   "source": [
    "ems_data = EMSData.load_instance('ems_data.pkl')\n",
    "\n",
    "n_stations = len(ems_data.stations)\n",
    "n_demand_nodes = len(ems_data.demand_nodes)\n",
    "demand = ems_data.demand_nodes.demand\n",
    "print(f'# stations: {n_stations}')\n",
    "print(f'# demand nodes: {n_demand_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "The Simulation class pulls relevant data from an EMSData instance and runs the simulation. Simulations are used to evaluate a solution (i.e., the number of ambulances at each station) as well as generate a dataset for the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickled Simulation instance is used by HTCondor jobs\n",
    "sim = Simulation(ems_data)\n",
    "sim.save_instance('simulation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covered0</th>\n",
       "      <th>total0</th>\n",
       "      <th>covered1</th>\n",
       "      <th>total1</th>\n",
       "      <th>covered2</th>\n",
       "      <th>total2</th>\n",
       "      <th>covered3</th>\n",
       "      <th>total3</th>\n",
       "      <th>covered4</th>\n",
       "      <th>total4</th>\n",
       "      <th>...</th>\n",
       "      <th>covered57</th>\n",
       "      <th>total57</th>\n",
       "      <th>covered58</th>\n",
       "      <th>total58</th>\n",
       "      <th>covered59</th>\n",
       "      <th>total59</th>\n",
       "      <th>covered60</th>\n",
       "      <th>total60</th>\n",
       "      <th>covered61</th>\n",
       "      <th>total61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>123</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>71</td>\n",
       "      <td>124</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "      <td>106</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>122</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>133</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   covered0  total0  covered1  total1  covered2  total2  covered3  total3  \\\n",
       "0         4       4         5       5        28      38        37      48   \n",
       "1         8       8         3       4        21      36        61      73   \n",
       "2         3       3         4       5        29      39        35      55   \n",
       "3         3       4         7       7        29      37        30      39   \n",
       "4         5       5         7       8        25      36        46      61   \n",
       "5         2       3         4       4        32      39        24      33   \n",
       "6         3       3         6       7        30      39        31      48   \n",
       "7         7       7         5       6        36      42        39      50   \n",
       "8         2       3        10      11        30      37        45      56   \n",
       "9         2       3         5       5        22      31        42      60   \n",
       "\n",
       "   covered4  total4  ...  covered57  total57  covered58  total58  covered59  \\\n",
       "0         1       1  ...         14       20         69      110         12   \n",
       "1         1       1  ...          8       19         72      113          8   \n",
       "2         0       1  ...         13       17         66      123         18   \n",
       "3         0       0  ...          8       12         68      105         12   \n",
       "4         2       2  ...          8       21         71      124         16   \n",
       "5         2       2  ...         10       18         48      113         16   \n",
       "6         2       2  ...         10       15         59      106         10   \n",
       "7         4       4  ...          8       13         78      122         18   \n",
       "8         0       0  ...          8       15         86      133         12   \n",
       "9         1       1  ...          6        8         75      116         13   \n",
       "\n",
       "   total59  covered60  total60  covered61  total61  \n",
       "0       22         22       47          2        4  \n",
       "1       20         20       32          5        9  \n",
       "2       27         13       27          3        5  \n",
       "3       22         25       39          3        3  \n",
       "4       23         15       20          2        4  \n",
       "5       23         15       34          0        0  \n",
       "6       25         19       34          4        7  \n",
       "7       27         10       23          0        1  \n",
       "8       20         18       34          3        5  \n",
       "9       20         14       39          1        1  \n",
       "\n",
       "[10 rows x 124 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run multiple replications of the simulation using a solution that places 2 ambulances at each station\n",
    "sim.run([2]*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8345282137619163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run multiple replications and evaluate coverage\n",
    "def evaluate_solution(solution):\n",
    "    sim_result = sim.run(solution)\n",
    "    result = sim_result.sum()  # Sum over replications\n",
    "    result = np.array([result[f'covered{i}']/result[f'total{i}'] for i in range(n_demand_nodes)])\n",
    "    result = np.nan_to_num(result, nan=0.0)\n",
    "    coverage = demand@result / demand.sum()  # Estimated long-term coverage\n",
    "    return coverage\n",
    "\n",
    "evaluate_solution([2]*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was generated using HTCondor and is stored in `dataset.csv`. `n_jobs = 100` jobs are run, each job performs the simulation for `solutions_per_job = 5000` solutions, and `n_replications = 10` replications are ran per solution. The resulting dataset has `n_jobs * solutions_per_job` samples, one per solution.\n",
    "\n",
    "To generate `dataset.csv`:\n",
    "1. Run `htcondor_setup.py` to generate the `settings<Process>.csv` files. These files contain the solutions to be simulated on each HTCondor job. Note that the script assumes `simulation.pkl` has already been created.\n",
    "2. Move the following files to the HTCondor submit server:\n",
    "    - `simulation.sub`\n",
    "    - `run_job.sh`\n",
    "    - `run_job.py`\n",
    "    - `simulation.py`\n",
    "    - `simulation.pkl`\n",
    "    - `settings$(Process).csv` for each `Process`\n",
    "    \n",
    "    Then run `condor_submit simulation.sub`.\n",
    "3. Once the jobs are done, move the `results<Process>.csv` files to a new folder named `sim_results`. Then run `create_dataset.py` to create the dataset from the `results<Process>.csv` files. For each solution, the script sums the `covered<i>` and `total<i>` columns over the replications and defines `coverage<i>` as the ratio of the two sums. The resulting dataset has columns `station<i>` for `i` in `range(n_stations)`, and `coverage<i>` for `i` in `range(n_demand_nodes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station0</th>\n",
       "      <th>station1</th>\n",
       "      <th>station2</th>\n",
       "      <th>station3</th>\n",
       "      <th>station4</th>\n",
       "      <th>station5</th>\n",
       "      <th>station6</th>\n",
       "      <th>station7</th>\n",
       "      <th>coverage0</th>\n",
       "      <th>coverage1</th>\n",
       "      <th>...</th>\n",
       "      <th>coverage52</th>\n",
       "      <th>coverage53</th>\n",
       "      <th>coverage54</th>\n",
       "      <th>coverage55</th>\n",
       "      <th>coverage56</th>\n",
       "      <th>coverage57</th>\n",
       "      <th>coverage58</th>\n",
       "      <th>coverage59</th>\n",
       "      <th>coverage60</th>\n",
       "      <th>coverage61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.725869</td>\n",
       "      <td>0.740864</td>\n",
       "      <td>0.746797</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.611754</td>\n",
       "      <td>0.633484</td>\n",
       "      <td>0.517751</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>0.660606</td>\n",
       "      <td>0.662931</td>\n",
       "      <td>0.742489</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.711240</td>\n",
       "      <td>0.744604</td>\n",
       "      <td>0.792117</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.637857</td>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.535256</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.705545</td>\n",
       "      <td>0.728555</td>\n",
       "      <td>0.776692</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.621827</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.537705</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.739754</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.792131</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.635802</td>\n",
       "      <td>0.648528</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.722531</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.808642</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.650709</td>\n",
       "      <td>0.647321</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.579805</td>\n",
       "      <td>0.498184</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.520524</td>\n",
       "      <td>0.478814</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.654344</td>\n",
       "      <td>0.669653</td>\n",
       "      <td>0.692937</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>0.615044</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.680435</td>\n",
       "      <td>0.605206</td>\n",
       "      <td>0.540364</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.547982</td>\n",
       "      <td>0.439462</td>\n",
       "      <td>0.483974</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.484190</td>\n",
       "      <td>0.412736</td>\n",
       "      <td>0.427706</td>\n",
       "      <td>0.398844</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.411552</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.324405</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station0  station1  station2  station3  station4  station5  station6  \\\n",
       "0             17         0         0         5         3         2         3   \n",
       "1              3         0         6         1         4         9         4   \n",
       "2              3         2         1         9         6         3         0   \n",
       "3              5         5         0         3         1         3         6   \n",
       "4              1         5         1        11         3         3         4   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "499995         3         0         3         5         7         3         2   \n",
       "499996         1         4         1         4         3         0         4   \n",
       "499997         0         3         0         1         1         2        11   \n",
       "499998         3         0         7         6         4         0         4   \n",
       "499999         6         2        13         0         0         0         4   \n",
       "\n",
       "        station7  coverage0  coverage1  ...  coverage52  coverage53  \\\n",
       "0              0   0.685714   0.722222  ...    0.900000    0.725869   \n",
       "1              3   0.717949   0.608696  ...    0.666667    0.730994   \n",
       "2              6   0.940000   0.936170  ...    0.655172    0.711240   \n",
       "3              7   0.928571   0.913793  ...    0.709677    0.705545   \n",
       "4              2   0.931818   0.943396  ...    0.692308    0.739754   \n",
       "...          ...        ...        ...  ...         ...         ...   \n",
       "499995         7   0.804878   0.677966  ...    0.666667    0.726115   \n",
       "499996        13   0.875000   0.931034  ...    0.750000    0.660194   \n",
       "499997        12   0.864865   0.892857  ...    0.608696    0.654344   \n",
       "499998         6   0.605263   0.700000  ...    0.739130    0.680435   \n",
       "499999         5   0.863636   0.978261  ...    0.346154    0.484190   \n",
       "\n",
       "        coverage54  coverage55  coverage56  coverage57  coverage58  \\\n",
       "0         0.740864    0.746797    0.754967    0.654088    0.611754   \n",
       "1         0.759259    0.833333    0.866242    0.660606    0.662931   \n",
       "2         0.744604    0.792117    0.801205    0.658228    0.637857   \n",
       "3         0.728555    0.776692    0.812903    0.618182    0.621827   \n",
       "4         0.721154    0.792131    0.805556    0.635802    0.648528   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "499995    0.722531    0.792593    0.808642    0.691275    0.650709   \n",
       "499996    0.579805    0.498184    0.455621    0.621622    0.520524   \n",
       "499997    0.669653    0.692937    0.734940    0.674847    0.615044   \n",
       "499998    0.605206    0.540364    0.435714    0.506173    0.547982   \n",
       "499999    0.412736    0.427706    0.398844    0.436364    0.411552   \n",
       "\n",
       "        coverage59  coverage60  coverage61  \n",
       "0         0.633484    0.517751    0.380952  \n",
       "1         0.742489    0.558405    0.652174  \n",
       "2         0.693277    0.535256    0.424242  \n",
       "3         0.727700    0.537705    0.408163  \n",
       "4         0.688372    0.599359    0.510638  \n",
       "...            ...         ...         ...  \n",
       "499995    0.647321    0.543478    0.714286  \n",
       "499996    0.478814    0.436364    0.416667  \n",
       "499997    0.552846    0.500000    0.571429  \n",
       "499998    0.439462    0.483974    0.555556  \n",
       "499999    0.375000    0.324405    0.258065  \n",
       "\n",
       "[500000 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "The MLP takes as input the solution and outputs the coverage probabilities for each demand node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 8]),\n",
       " torch.Size([10000, 8]),\n",
       " torch.Size([480000, 8]),\n",
       " torch.Size([10000, 62]),\n",
       " torch.Size([10000, 62]),\n",
       " torch.Size([480000, 62]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move dataset into tensors compatible with model and split into train/dev/test sets\n",
    "X = dataset[[f'station{i}' for i in range(n_stations)]].to_numpy()\n",
    "y = dataset[[f'coverage{i}' for i in range(n_demand_nodes)]].to_numpy()\n",
    "X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=20000)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, random_state=0, train_size=0.5)\n",
    "X_train.shape, X_dev.shape, X_test.shape, y_train.shape, y_dev.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-term coverage of best training sample: 0.9372910108223353\n"
     ]
    }
   ],
   "source": [
    "# Find best performing training sample\n",
    "sim_scores = y_train.cpu().numpy()@demand / demand.sum()\n",
    "print(f'Long-term coverage of best training sample: {sim_scores.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 296.99it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 849.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train loss: 0.8637865153651084, initial dev loss: 0.8640322444792716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 1/10): 100%|██████████| 313/313 [00:00<00:00, 613.72it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1788.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.49376802043914797, dev loss: 0.47185515456661103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 2/10): 100%|██████████| 313/313 [00:00<00:00, 686.41it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1788.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.47437783117294313, dev loss: 0.4694589346608808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 3/10): 100%|██████████| 313/313 [00:00<00:00, 716.25it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1788.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.47156154794692995, dev loss: 0.46868146313082787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 4/10): 100%|██████████| 313/313 [00:00<00:00, 711.36it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1778.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.470481485414505, dev loss: 0.4683176966513357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 5/10): 100%|██████████| 313/313 [00:00<00:00, 716.25it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1778.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.4699727956771851, dev loss: 0.46812244085496474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 6/10): 100%|██████████| 313/313 [00:00<00:00, 698.67it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1788.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.4696300947666168, dev loss: 0.46789827733193673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 7/10): 100%|██████████| 313/313 [00:00<00:00, 717.89it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1788.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.46948283429145815, dev loss: 0.4678463356264176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 8/10): 100%|██████████| 313/313 [00:00<00:00, 724.54it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1778.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.4693063184261322, dev loss: 0.4678296843990203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 9/10): 100%|██████████| 313/313 [00:00<00:00, 627.26it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1247.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.46921506843566896, dev loss: 0.4677855516987462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 10/10): 100%|██████████| 313/313 [00:00<00:00, 613.73it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:00<00:00, 1222.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.4691448592185974, dev loss: 0.4678161828810169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "mlp = MultilabelMLP(n_stations, [200], n_demand_nodes, dropout=0.1).to(device)\n",
    "init_train_loss = mlp.evaluate_model(X_train, y_train)\n",
    "init_dev_loss = mlp.evaluate_model(X_dev, y_dev)\n",
    "print(f'Initial train loss: {init_train_loss}, initial dev loss: {init_dev_loss}')\n",
    "mlp.train_model(X_train, y_train, X_dev, y_dev, batch_size=32, max_epochs=10, tolerance=0.0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilabelMLP(\n",
       "  (0): Linear(in_features=8, out_features=200, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.0, inplace=False)\n",
       "  (3): Linear(in_features=200, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of loading a saved model\n",
    "mlp = MultilabelMLP.load_model('model.pt').to(device)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 3750/3750 [00:02<00:00, 1844.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02321643, 0.013941824, 0.94692093, 1.2331989247311828e-05)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test set and evaluate some metrics\n",
    "y_hat = mlp.predict(X_test)\n",
    "abs_diff = np.absolute(y_hat.cpu().numpy() - y_test.cpu().numpy())\n",
    "abs_diff.mean(), np.median(abs_diff), abs_diff.max(), (abs_diff > 0.5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "The trained MLP is embedded within a MIP which attempts to find the solution that the MLP predicts will have the highest coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-11-17\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 5 3600 6-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 63 rows, 1868 columns and 2012 nonzeros\n",
      "Model fingerprint: 0xe94c8367\n",
      "Variable types: 0 continuous, 1868 integer (1860 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [9e-10, 4e+02]\n",
      "  Bounds range     [1e+00, 3e+01]\n",
      "  RHS range        [3e+01, 3e+01]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 3 rows and 92 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 60 rows, 1776 columns, 1902 nonzeros\n",
      "Variable types: 0 continuous, 1776 integer (1770 binary)\n",
      "Found heuristic solution: objective 378.9999996\n",
      "\n",
      "Root relaxation: objective 7.264092e+03, 160 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    7264.0922232 7264.09222  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (160 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 7264.09 379 -0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.264092223167e+03, best bound 7.264092223167e+03, gap 0.0000%\n",
      "MEXCLP solution: [3, 0, 0, 3, 6, 10, 3, 5]\n",
      "Long-term coverage of MEXCLP with p=0.5: 0.9306966695578651\n"
     ]
    }
   ],
   "source": [
    "# Daskin's MEXCLP model\n",
    "coverage = compute_coverage(ems_data)\n",
    "solution = mexclp(demand=demand, coverage=coverage, n_ambulances=30, busy_fraction=0.5, verbose=True)\n",
    "print(f'MEXCLP solution: {solution}')\n",
    "score = evaluate_solution(solution)\n",
    "print(f'Long-term coverage of MEXCLP with p=0.5: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 5 3600 6-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 1553 rows, 740 columns and 17050 nonzeros\n",
      "Model fingerprint: 0xb3f3ab67\n",
      "Variable types: 532 continuous, 208 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-06, 4e+01]\n",
      "  Objective range  [1e+00, 8e+02]\n",
      "  Bounds range     [1e+00, 3e+01]\n",
      "  RHS range        [4e-03, 4e+01]\n",
      "Presolve removed 41 rows and 8 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 1512 rows, 732 columns, 17018 nonzeros\n",
      "Variable types: 524 continuous, 208 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 7.144239e+03, 984 iterations, 0.04 seconds (0.08 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 7144.23894    0   97          - 7144.23894      -     -    0s\n",
      "H    0     0                    6833.7981165 7144.23894  4.54%     -    0s\n",
      "     0     0 7034.97804    0   97 6833.79812 7034.97804  2.94%     -    0s\n",
      "     0     0 7034.96729    0   97 6833.79812 7034.96729  2.94%     -    0s\n",
      "     0     0 7034.09671    0   98 6833.79812 7034.09671  2.93%     -    0s\n",
      "     0     0 7033.06605    0   96 6833.79812 7033.06605  2.92%     -    0s\n",
      "     0     0 7033.05310    0   95 6833.79812 7033.05310  2.92%     -    0s\n",
      "     0     0 7032.72501    0   95 6833.79812 7032.72501  2.91%     -    1s\n",
      "H    0     0                    6836.0187262 7032.72501  2.88%     -    1s\n",
      "     0     0 7032.66523    0   95 6836.01873 7032.66523  2.88%     -    1s\n",
      "     0     0 7032.66523    0   95 6836.01873 7032.66523  2.88%     -    1s\n",
      "     0     0 7031.83976    0   97 6836.01873 7031.83976  2.86%     -    1s\n",
      "     0     0 7031.83598    0   97 6836.01873 7031.83598  2.86%     -    1s\n",
      "H    0     0                    6862.9523145 7031.83598  2.46%     -    1s\n",
      "     0     0 7031.78730    0   98 6862.95231 7031.78730  2.46%     -    1s\n",
      "     0     0 7031.78730    0   98 6862.95231 7031.78730  2.46%     -    2s\n",
      "     0     0 7031.78730    0   98 6862.95231 7031.78730  2.46%     -    2s\n",
      "     0     2 7031.78730    0   98 6862.95231 7031.78730  2.46%     -    2s\n",
      "  1264   761 6880.04380   30   97 6862.95231 6969.33547  1.55%  15.1    5s\n",
      "  2132   970     cutoff   44      6862.95231 6969.33547  1.55%  19.0   10s\n",
      "H 2138   929                    6866.0475946 6969.33547  1.50%  19.1   10s\n",
      "* 6410  2271             100    6872.0780818 6937.09845  0.95%  18.4   13s\n",
      " 10625  3670 6880.36256   51   50 6872.07808 6913.55807  0.60%  17.3   15s\n",
      "*20978  3508              92    6874.6836034 6888.68006  0.20%  15.5   19s\n",
      "*21406  3112              82    6875.8195586 6887.92068  0.18%  15.4   19s\n",
      " 22790  2629     cutoff   74      6875.81956 6885.71336  0.14%  15.2   20s\n",
      "*22918  2383              92    6876.8605021 6885.61434  0.13%  15.2   20s\n",
      "*25098   613              93    6877.1791590 6881.87404  0.07%  14.8   21s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 1\n",
      "  Gomory: 172\n",
      "  Cover: 16\n",
      "  Implied bound: 5\n",
      "  Projected implied bound: 1\n",
      "  Clique: 1\n",
      "  MIR: 207\n",
      "  Flow cover: 33\n",
      "  Inf proof: 1\n",
      "  RLT: 20\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 26637 nodes (386395 simplex iterations) in 21.49 seconds (22.23 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 9: 6877.18 6876.86 6875.82 ... 6833.8\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 6.877179158973e+03, best bound 6.877179158973e+03, gap 0.0000%\n",
      "Our model's solution: [0, 0, 1, 6, 8, 10, 3, 2]\n",
      "Long-term coverage of our model: 0.9381773833641379\n"
     ]
    }
   ],
   "source": [
    "# Our model with MLP embedded\n",
    "solution = mexclp_mlp(demand=demand, mlp=mlp, n_ambulances=30, time_limit=60, verbose=True)\n",
    "print(f\"Our model's solution: {solution}\")\n",
    "score = evaluate_solution(solution)\n",
    "print(f'Long-term coverage of our model: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
